import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import sys
import os
import time
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Add parent directory to path for utils import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from document_based_chunker import DocumentBasedChunker, DocumentBasedChunkMetrics
from utils.document_loader import DocumentLoader, load_document
from utils.evaluation_metrics import ChunkingEvaluator, evaluate_chunks
from utils.visualization import ChunkingVisualizer, plot_chunk_distribution

# Import other chunkers for comparison
fixed_chunker_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '01_fixed_size_chunking')
sys.path.append(fixed_chunker_path)
from fixed_size_chunker import FixedSizeChunker

recursive_chunker_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '02_recursive_chunking')
sys.path.append(recursive_chunker_path)
from recursive_chunker import RecursiveChunker


# Configure Streamlit page
st.set_page_config(
    page_title="Document-Based Chunking Demo",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 0.25rem solid #1f77b4;
    }
    .chunk-preview {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #dee2e6;
        margin: 0.5rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 0.25rem solid #ffc107;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d1edff;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 0.25rem solid #28a745;
        margin: 1rem 0;
    }
    .element-tag {
        background-color: #e9ecef;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        font-family: monospace;
        font-size: 0.9rem;
        margin: 0.1rem;
        display: inline-block;
    }
</style>
""", unsafe_allow_html=True)


def create_element_distribution_chart(element_distribution):
    """Create chart showing element distribution."""
    if not element_distribution:
        return None
    
    elements = list(element_distribution.keys())
    counts = list(element_distribution.values())
    
    fig = go.Figure(data=[
        go.Bar(
            x=elements,
            y=counts,
            text=counts,
            textposition='outside',
            marker_color='lightgreen'
        )
    ])
    
    fig.update_layout(
        title="Document Element Distribution",
        xaxis_title="Element Type",
        yaxis_title="Count",
        height=400
    )
    
    return fig


def create_quality_metrics_gauge(metrics: DocumentBasedChunkMetrics):
    """Create gauge charts for quality metrics."""
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("Structure Preservation", "Semantic Coherence", 
                       "Header Inclusion", "Broken Elements"),
        specs=[[{"type": "indicator"}, {"type": "indicator"}],
               [{"type": "indicator"}, {"type": "indicator"}]]
    )
    
    # Structure preservation gauge
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=metrics.structure_preservation_score * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Structure Preservation (%)"},
            gauge={'axis': {'range': [None, 100]},
                   'bar': {'color': "darkblue"},
                   'steps': [{'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "green"}]}
        ),
        row=1, col=1
    )
    
    # Semantic coherence gauge
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=metrics.semantic_coherence_score * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Semantic Coherence (%)"},
            gauge={'axis': {'range': [None, 100]},
                   'bar': {'color': "darkgreen"},
                   'steps': [{'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "green"}]}
        ),
        row=1, col=2
    )
    
    # Header inclusion gauge
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=metrics.header_inclusion_ratio * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Header Inclusion (%)"},
            gauge={'axis': {'range': [None, 100]},
                   'bar': {'color': "darkred"},
                   'steps': [{'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "green"}]}
        ),
        row=2, col=1
    )
    
    # Broken elements gauge (inverted - lower is better)
    fig.add_trace(
        go.Indicator(
            mode="gauge+number",
            value=(1 - metrics.broken_elements_ratio) * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Element Integrity (%)"},
            gauge={'axis': {'range': [None, 100]},
                   'bar': {'color': "darkorange"},
                   'steps': [{'range': [0, 50], 'color': "red"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "green"}]}
        ),
        row=2, col=2
    )
    
    fig.update_layout(height=600, showlegend=False)
    return fig


def create_comparison_metrics_chart(doc_metrics, fixed_metrics, recursive_metrics):
    """Create comparison chart between different chunking methods."""
    methods = ["Document-Based", "Fixed-Size", "Recursive"]
    structure_scores = [
        doc_metrics.structure_preservation_score,
        0.45,  # Estimated for fixed-size
        recursive_metrics.structure_preservation_score
    ]
    quality_scores = [
        doc_metrics.semantic_coherence_score,
        0.60,  # Estimated for fixed-size
        1.0 - recursive_metrics.broken_sentences_ratio  # Quality based on sentence integrity
    ]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name="Structure Preservation",
        x=methods,
        y=structure_scores,
        marker_color='lightblue'
    ))
    
    fig.add_trace(go.Bar(
        name="Quality Score",
        x=methods,
        y=quality_scores,
        marker_color='lightgreen'
    ))
    
    fig.update_layout(
        title="Chunking Method Comparison",
        barmode='group',
        yaxis_title="Score",
        height=400
    )
    
    return fig


def load_sample_document():
    """Load a sample document for testing."""
    return """# Introduction to Document-Based Chunking

Document-based chunking is an advanced text chunking technique that preserves document structure and semantic meaning.

## Key Features

### Structure Preservation
- Maintains document organization
- Preserves headers and sections
- Keeps related content together

### Semantic Intelligence
- Groups related elements
- Preserves context across boundaries
- Maintains readability

## Technical Implementation

### Document Elements

The chunker recognizes various document elements:

1. **Headers**: Markdown headers (# ## ###)
2. **Paragraphs**: Text blocks separated by blank lines
3. **Lists**: Ordered and unordered lists
4. **Code Blocks**: Markdown code blocks (```)
5. **Quotes**: Blockquotes (>)
6. **Tables**: Markdown table rows

### Processing Pipeline

```python
# Initialize chunker
chunker = DocumentBasedChunker(
    chunk_size=1000,
    chunk_overlap=200,
    preserve_headers=True
)

# Process document
chunks = chunker.chunk_text(document_text)
```

## Evaluation Metrics

The chunker provides comprehensive metrics:

- **Structure Preservation Score**: How well document structure is maintained
- **Semantic Coherence Score**: Quality of semantic grouping
- **Header Inclusion Ratio**: Percentage of chunks with headers
- **Element Distribution**: Analysis of document elements

## Best Practices

1. **Choose appropriate chunk size** based on your use case
2. **Use overlap** when context preservation is important
3. **Monitor metrics** to optimize performance
4. **Test with your specific data** to find optimal parameters

## Conclusion

Document-based chunking provides superior results for RAG applications by maintaining document structure and semantic coherence.
"""


def main():
    """Main Streamlit application."""

    # Header
    st.title("üìÑ Document-Based Chunking Strategy")
    st.markdown("""
    **Advanced text chunking that preserves document structure and semantic meaning.**

    This strategy maintains document organization by:
    - üìÑ Preserving headers, sections, and document structure
    - üéØ Grouping related content together
    - üìä Providing comprehensive quality metrics
    - üîç Comparing performance with other chunking methods
    """)

    # Sidebar for parameters
    st.sidebar.header("üìÑ Document-Based Chunking Parameters")

    chunk_size = st.sidebar.slider(
        "Chunk Size (characters)",
        min_value=200,
        max_value=2000,
        value=1000,
        step=50,
        help="Target maximum size for chunks"
    )

    chunk_overlap = st.sidebar.slider(
        "Chunk Overlap (characters)",
        min_value=0,
        max_value=min(500, chunk_size-100),
        value=200,
        step=25,
        help="Characters to overlap between consecutive chunks"
    )

    # Document structure parameters
    st.sidebar.subheader("üìã Document Structure")

    preserve_headers = st.sidebar.checkbox(
        "Preserve Headers",
        value=True,
        help="Include headers in chunks to maintain document structure"
    )

    max_header_level = st.sidebar.slider(
        "Max Header Level",
        min_value=1,
        max_value=6,
        value=3,
        help="Maximum header level to consider for structure"
    )

    semantic_threshold = st.sidebar.slider(
        "Semantic Threshold",
        min_value=0.1,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Threshold for semantic coherence scoring"
    )

    min_chunk_size = st.sidebar.slider(
        "Min Chunk Size",
        min_value=50,
        max_value=500,
        value=200,
        step=50,
        help="Minimum size for a chunk"
    )

    # Comparison option
    st.sidebar.subheader("üìä Comparison Analysis")
    enable_comparison = st.sidebar.checkbox(
        "Compare with Other Methods",
        value=True,
        help="Show side-by-side comparison with fixed-size and recursive chunking"
    )

    # Text input section
    st.header("üìÑ Document Input")

    input_method = st.radio(
        "Choose input method:",
        ["Sample Document", "Upload File", "Enter Custom Text"],
        horizontal=True
    )

    text_content = ""

    if input_method == "Sample Document":
        text_content = load_sample_document()
        st.info("Using sample document with clear structure and various elements")

    elif input_method == "Upload File":
        uploaded_file = st.file_uploader("Choose a file", type=["txt", "md", "pdf", "docx"])
        if uploaded_file:
            try:
                document_loader = DocumentLoader()
                text_content, metadata = document_loader.load_document(
                    uploaded_file, "upload")
                st.success(
                    f"File loaded successfully! ({metadata.character_count:,} characters, {metadata.word_count:,} words)")
            except Exception as e:
                st.error(f"Error loading file: {str(e)}")

    elif input_method == "Enter Custom Text":
        text_content = st.text_area(
            "Enter your text:",
            height=200,
            placeholder="Paste your text here..."
        )

    # Validation warnings
    if chunk_overlap >= chunk_size:
        st.error("‚ö†Ô∏è Chunk overlap must be less than chunk size!")
        return

    if min_chunk_size >= chunk_size:
        st.error("‚ö†Ô∏è Min chunk size must be less than chunk size!")
        return

    # Process text if available
    if text_content and text_content.strip():

        # Initialize chunkers
        document_chunker = DocumentBasedChunker(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            preserve_headers=preserve_headers,
            max_header_level=max_header_level,
            semantic_threshold=semantic_threshold,
            min_chunk_size=min_chunk_size
        )

        if enable_comparison:
            fixed_chunker = FixedSizeChunker(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )
            recursive_chunker = RecursiveChunker(
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )

        # Show processing button
        if st.button("üìÑ Process Document", type="primary"):
            with st.spinner("Processing document with document-based chunking..."):
                # Document-based chunking
                start_time = time.time()
                doc_chunks, doc_metrics = document_chunker.chunk_with_metrics(text_content)
                element_analysis = document_chunker.analyze_chunks(doc_chunks)
                doc_time = time.time() - start_time

                # Comparison chunking if enabled
                if enable_comparison:
                    with st.spinner("Comparing with other chunking methods..."):
                        fixed_chunks, fixed_metrics = fixed_chunker.chunk_with_metrics(text_content)
                        recursive_chunks, recursive_metrics = recursive_chunker.chunk_with_metrics(text_content)

                # Store results in session state
                st.session_state.doc_chunks = doc_chunks
                st.session_state.doc_metrics = doc_metrics
                st.session_state.element_analysis = element_analysis

                if enable_comparison:
                    st.session_state.fixed_chunks = fixed_chunks
                    st.session_state.fixed_metrics = fixed_metrics
                    st.session_state.recursive_chunks = recursive_chunks
                    st.session_state.recursive_metrics = recursive_metrics
                    st.session_state.comparison_enabled = True
                else:
                    st.session_state.comparison_enabled = False

        # Display results if available
        if hasattr(st.session_state, 'doc_chunks'):
            doc_chunks = st.session_state.doc_chunks
            doc_metrics = st.session_state.doc_metrics
            element_analysis = st.session_state.element_analysis

            comparison_enabled = getattr(st.session_state, 'comparison_enabled', False)
            if comparison_enabled:
                fixed_chunks = st.session_state.fixed_chunks
                fixed_metrics = st.session_state.fixed_metrics
                recursive_chunks = st.session_state.recursive_chunks
                recursive_metrics = st.session_state.recursive_metrics

            # Performance Metrics Overview
            st.header("üìà Performance Metrics")

            if comparison_enabled:
                # Comparison metrics
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.subheader("üìÑ Document-Based")
                    st.metric("Total Chunks", doc_metrics.total_chunks)
                    st.metric("Avg Chunk Size", f"{doc_metrics.avg_chunk_size:.0f}")
                    st.metric("Structure Score", f"{doc_metrics.structure_preservation_score:.1%}")
                    st.metric("Semantic Score", f"{doc_metrics.semantic_coherence_score:.1%}")

                with col2:
                    st.subheader("üìê Fixed-Size")
                    st.metric("Total Chunks", fixed_metrics.total_chunks)
                    st.metric("Avg Chunk Size", f"{fixed_metrics.avg_chunk_size:.0f}")
                    st.metric("Structure Score", "~45%")
                    st.metric("Semantic Score", "~60%")

                with col3:
                    st.subheader("üîÑ Recursive")
                    st.metric("Total Chunks", recursive_metrics.total_chunks)
                    st.metric("Avg Chunk Size", f"{recursive_metrics.avg_chunk_size:.0f}")
                    st.metric("Structure Score", f"{recursive_metrics.structure_preservation_score:.1%}")
                    st.metric("Broken Sentences", f"{recursive_metrics.broken_sentences_ratio:.1%}")

            else:
                # Single method metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total Chunks", doc_metrics.total_chunks)
                with col2:
                    st.metric("Avg Chunk Size", f"{doc_metrics.avg_chunk_size:.0f}")
                with col3:
                    st.metric("Processing Time", f"{doc_metrics.processing_time:.2f}s")
                with col4:
                    st.metric("Memory Usage", f"{doc_metrics.memory_usage_mb:.1f} MB")

            # Quality Metrics
            st.header("üéØ Quality Metrics")
            
            quality_fig = create_quality_metrics_gauge(doc_metrics)
            st.plotly_chart(quality_fig, use_container_width=True)

            # Element Distribution
            st.header("üìã Element Analysis")
            
            if doc_metrics.element_distribution:
                element_fig = create_element_distribution_chart(doc_metrics.element_distribution)
                st.plotly_chart(element_fig, use_container_width=True)

            # Comparison Chart
            if comparison_enabled:
                st.header("üìä Method Comparison")
                comparison_fig = create_comparison_metrics_chart(
                    doc_metrics, fixed_metrics, recursive_metrics
                )
                st.plotly_chart(comparison_fig, use_container_width=True)

            # Chunk Preview
            st.header("üìÑ Chunk Preview")
            
            if doc_chunks:
                # Chunk statistics
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Total Chunks", len(doc_chunks))
                
                with col2:
                    chunk_sizes = [len(chunk) for chunk in doc_chunks]
                    st.metric("Min Size", f"{min(chunk_sizes)} chars")
                
                with col3:
                    st.metric("Max Size", f"{max(chunk_sizes)} chars")

                # Chunk previews
                st.subheader("üìÑ Chunk Previews")
                
                # Allow user to select chunk range
                total_chunks = len(doc_chunks)
                start_chunk = st.slider("Start Chunk", 1, total_chunks, 1)
                end_chunk = st.slider("End Chunk", start_chunk, total_chunks, min(start_chunk + 4, total_chunks))
                
                # Display selected chunks
                for i in range(start_chunk - 1, end_chunk):
                    with st.expander(f"Chunk {i + 1} ({len(doc_chunks[i])} characters)"):
                        st.markdown(f"""
                        <div class="chunk-preview">
                        {doc_chunks[i]}
                        </div>
                        """, unsafe_allow_html=True)


if __name__ == "__main__":
    main() 